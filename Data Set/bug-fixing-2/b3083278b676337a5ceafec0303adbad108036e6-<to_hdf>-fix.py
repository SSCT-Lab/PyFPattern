

def to_hdf(self, path_or_buf, key, **kwargs):
    "Write the contained data to an HDF5 file using HDFStore.\n\n        Parameters\n        ----------\n        path_or_buf : the path (string) or HDFStore object\n        key : string\n            identifier for the group in the store\n        mode : optional, {'a', 'w', 'r+'}, default 'a'\n\n          ``'w'``\n              Write; a new file is created (an existing file with the same\n              name would be deleted).\n          ``'a'``\n              Append; an existing file is opened for reading and writing,\n              and if the file does not exist it is created.\n          ``'r+'``\n              It is similar to ``'a'``, but the file must already exist.\n        format : 'fixed(f)|table(t)', default is 'fixed'\n            fixed(f) : Fixed format\n                       Fast writing/reading. Not-appendable, nor searchable\n            table(t) : Table format\n                       Write as a PyTables Table structure which may perform\n                       worse but allow more flexible operations like searching\n                       / selecting subsets of the data\n        append : boolean, default False\n            For Table formats, append the input data to the existing\n        data_columns :  list of columns, or True, default None\n            List of columns to create as indexed data columns for on-disk\n            queries, or True to use all columns. By default only the axes\n            of the object are indexed. See `here\n            <http://pandas.pydata.org/pandas-docs/stable/io.html#query-via-data-columns>`__.\n\n            Applicable only to format='table'.\n        complevel : int, 1-9, default 0\n            If a complib is specified compression will be applied\n            where possible\n        complib : {'zlib', 'bzip2', 'lzo', 'blosc', None}, default None\n            If complevel is > 0 apply compression to objects written\n            in the store wherever possible\n        fletcher32 : bool, default False\n            If applying compression use the fletcher32 checksum\n        dropna : boolean, default False.\n            If true, ALL nan rows will not be written to store.\n        "
    from pandas.io import pytables
    return pytables.to_hdf(path_or_buf, key, self, **kwargs)
