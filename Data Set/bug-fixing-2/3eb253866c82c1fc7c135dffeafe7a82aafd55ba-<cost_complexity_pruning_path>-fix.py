

def cost_complexity_pruning_path(self, X, y, sample_weight=None):
    'Compute the pruning path during Minimal Cost-Complexity Pruning.\n\n        See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n        process.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The training input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csc_matrix``.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            The target values (class labels) as integers or strings.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights. If None, then samples are equally weighted. Splits\n            that would create child nodes with net zero or negative weight are\n            ignored while searching for a split in each node. Splits are also\n            ignored if they would result in any single class carrying a\n            negative weight in either child node.\n\n        Returns\n        -------\n        ccp_path : Bunch\n            Dictionary-like object, with attributes:\n\n            ccp_alphas : ndarray\n                Effective alphas of subtree during pruning.\n\n            impurities : ndarray\n                Sum of the impurities of the subtree leaves for the\n                corresponding alpha value in ``ccp_alphas``.\n        '
    est = clone(self).set_params(ccp_alpha=0.0)
    est.fit(X, y, sample_weight=sample_weight)
    return Bunch(**ccp_pruning_path(est.tree_))
