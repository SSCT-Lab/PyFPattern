def conv2d_grad_wrt_weights(input, output_grad, filter_shape, input_shape=None, border_mode='valid', subsample=(1, 1), filter_flip=True, filter_dilation=(1, 1)):
    'Compute conv output gradient w.r.t its weights\n\n    This function will build the symbolic graph for getting the\n    gradient of the output of a convolution (output_grad) w.r.t its wights.\n\n    Parameters\n    ----------\n    input : symbolic 4D tensor\n        mini-batch of feature map stacks, of shape (batch size, input\n        channels, input rows, input columns).  This is the input of\n        the convolution in the forward pass.\n    output_grad : symbolic 4D tensor\n        mini-batch of feature map stacks, of shape (batch size, input\n        channels, input rows, input columns).  This is the gradient of\n        the output of convolution.\n    filter_shape : [None/int/Constant] * 2 + [Tensor/int/Constant] * 2\n        The shape of the filter parameter.  A tuple/list of len 4, with the\n        first two dimensions being None or int or Constant and the last two\n        dimensions being Tensor or int or Constant.\n        Not Optional, since given the output_grad shape and\n        the input_shape, multiple filter_shape may be plausible.\n    input_shape : None or [None/int/Constant] * 4\n        The shape of the input parameter. None or a tuple/list of len 4.\n        Optional, possibly used to choose an optimal implementation.\n        You can give ``None`` for any element of the list to specify\n        that this element is not known at compile time.\n    border_mode : str, int or tuple of two ints\n        Either of the following:\n\n          ``\'valid\'``\n            apply filter wherever it completely overlaps with the\n            input. Generates output of shape: input shape - filter\n            shape + 1\n\n          ``\'full\'``\n            apply filter wherever it partly overlaps with the input.\n            Generates output of shape: input shape + filter shape - 1\n\n          ``\'half\'``\n            pad input with a symmetric border of ``filter rows // 2``\n            rows and ``filter columns // 2`` columns, then perform a\n            valid convolution. For filters with an odd number of rows\n            and columns, this leads to the output shape being equal to\n            the input shape. It is known as \'same\' elsewhere.\n\n          ``int``\n            pad input with a symmetric border of zeros of the given\n            width, then perform a valid convolution.\n\n          ``(int1, int2)``\n            pad input with a symmetric border of ``int1`` rows and\n            ``int2`` columns, then perform a valid convolution.\n    subsample : tuple of len 2\n        The subsampling used in the forward pass of the convolutional\n        operation.  Also called strides elsewhere.\n    filter_flip : bool\n        If ``True``, will flip the filter rows and columns before\n        sliding them over the input. This operation is normally\n        referred to as a convolution, and this is the default. If\n        ``False``, the filters are not flipped and the operation is\n        referred to as a cross-correlation.\n    filter_dilation : tuple of len 2\n        The filter dilation used in the forward pass.\n        Also known as input striding.\n\n    Returns\n    -------\n    symbolic 4D tensor\n        set of feature maps generated by convolutional layer. Tensor\n        is of shape (batch size, output channels, output rows, output\n        columns)\n\n    Notes\n    -----\n\n    :note: If cuDNN is available, it will be used on the\n        GPU. Otherwise, it is the *CorrMM* convolution that will be used\n        "caffe style convolution".\n\n    :note: This is only supported in Theano 0.8 or the development\n        version until it is released.\n\n    '
    input = as_tensor_variable(input)
    output_grad = as_tensor_variable(output_grad)
    for dim in [0, 1]:
        assert isinstance(filter_shape[dim], (theano.tensor.TensorConstant, integer_types, type(None)))
    for dim in [2, 3]:
        assert isinstance(filter_shape[dim], (theano.tensor.TensorVariable, theano.tensor.TensorConstant, integer_types))
    if (input_shape is not None):
        for dim in [0, 1, 2, 3]:
            assert isinstance(input_shape[dim], (theano.tensor.TensorConstant, integer_types, type(None)))
    numerical_filter_shape = list(filter_shape)
    for dim in [2, 3]:
        if isinstance(filter_shape[dim], theano.tensor.TensorVariable):
            numerical_filter_shape[dim] = None
    gradWeight_op = AbstractConv2d_gradWeights(imshp=input_shape, kshp=numerical_filter_shape, border_mode=border_mode, subsample=subsample, filter_flip=filter_flip, filter_dilation=filter_dilation)
    return gradWeight_op(input, output_grad, filter_shape[:(- 2)])