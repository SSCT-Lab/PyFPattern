def update_col_factors(self, sp_input=None, transpose_input=False):
    'Updates the column factors.\n\n    Args:\n      sp_input: A SparseTensor representing a subset of columns of the full\n        input. Please refer to comments for update_row_factors for\n        restrictions.\n      transpose_input: If true, the input will be logically transposed and the\n        columns corresponding to the transposed input are updated.\n\n    Returns:\n      A tuple consisting of the following elements:\n      new_values: New values for the column factors.\n      update_op: An op that assigns the newly computed values to the column\n        factors.\n      unregularized_loss: A tensor (scalar) that contains the normalized\n        minibatch loss corresponding to sp_input, without the regularization\n        term. If sp_input contains the columns {A_{:, j}, j \\in J}, and the\n        input matrix A has m total columns, then the unregularized loss is:\n        (\\|\\sqrt W_J \\odot (A_J - U V_J^T)\\|_F^2 * m / |I|\n        The total loss is unregularized_loss + regularization.\n      regularization: A tensor (scalar) that contains the normalized\n        regularization term for the minibatch loss corresponding to sp_input.\n        If sp_input contains the columns {A_{:, j}, j \\in J}, and the input\n        matrix A has m total columns, then the regularization term is:\n        \\lambda \\|V_J\\|_F^2) * m / |J| + \\lambda \\|U\\|_F^2.\n      sum_weights: The sum of the weights W_J corresponding to sp_input,\n        normalized by a factor of m / |J|. The root weighted squared error is:\n        \\sqrt(unregularized_loss / sum_weights).\n    '
    return self._process_input_helper(False, sp_input=sp_input, transpose_input=transpose_input)